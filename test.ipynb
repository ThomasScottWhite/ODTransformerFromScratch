{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3abb93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=14.97s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Added 90 new experts, total now: 92\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 131\u001b[0m\n\u001b[1;32m    127\u001b[0m     tgt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tgt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    129\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(tensors)\n\u001b[0;32m--> 131\u001b[0m loss, loss_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    134\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniforge3/envs/mind/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mind/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[3], line 58\u001b[0m, in \u001b[0;36mSimpleSetCriterion.forward\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m     56\u001b[0m tgt_classes \u001b[38;5;241m=\u001b[39m targets[b][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m][idx_tgt]\n\u001b[1;32m     57\u001b[0m pred_classes \u001b[38;5;241m=\u001b[39m pred_logits[b][idx_pred]\n\u001b[0;32m---> 58\u001b[0m loss_cls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m tgt_boxes \u001b[38;5;241m=\u001b[39m targets[b][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m][idx_tgt]\n\u001b[1;32m     61\u001b[0m pred_bboxes \u001b[38;5;241m=\u001b[39m pred_boxes[b][idx_pred]\n",
      "File \u001b[0;32m~/miniforge3/envs/mind/lib/python3.11/site-packages/torch/nn/functional.py:3389\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3384\u001b[0m         reduced \u001b[38;5;241m=\u001b[39m reduced \u001b[38;5;241m/\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   3386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduced\n\u001b[0;32m-> 3389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcross_entropy\u001b[39m(\n\u001b[1;32m   3390\u001b[0m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m   3391\u001b[0m     target: Tensor,\n\u001b[1;32m   3392\u001b[0m     weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3393\u001b[0m     size_average: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3394\u001b[0m     ignore_index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m   3395\u001b[0m     reduce: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3396\u001b[0m     reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3397\u001b[0m     label_smoothing: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m   3398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m   3399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the cross entropy loss between input logits and target.\u001b[39;00m\n\u001b[1;32m   3400\u001b[0m \n\u001b[1;32m   3401\u001b[0m \u001b[38;5;124;03m    See :class:`~torch.nn.CrossEntropyLoss` for details.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3462\u001b[0m \u001b[38;5;124;03m        >>> loss.backward()\u001b[39;00m\n\u001b[1;32m   3463\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target, weight):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from coco import create_coco_dataloaders\n",
    "from model import MINDObjectDetector\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.ops import generalized_box_iou, box_iou\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "class SimpleMatcher:\n",
    "    def __call__(self, pred_logits, pred_boxes, targets):\n",
    "        indices = []\n",
    "        for b in range(pred_logits.size(0)):\n",
    "            tgt_boxes = targets[b][\"boxes\"]\n",
    "            tgt_labels = targets[b][\"labels\"]\n",
    "            out_prob = pred_logits[b].softmax(-1)  # [num_queries, num_classes]\n",
    "            out_bbox = pred_boxes[b]              # [num_queries, 4]\n",
    "\n",
    "            cost_cls = -out_prob[:, tgt_labels]   # Cross-entropy cost\n",
    "            cost_bbox = torch.cdist(out_bbox, tgt_boxes, p=1)  # L1 distance\n",
    "\n",
    "            C = cost_bbox + cost_cls\n",
    "            C = C.detach().cpu()\n",
    "            i, j = linear_sum_assignment(C)\n",
    "            indices.append((torch.as_tensor(i, dtype=torch.int64),\n",
    "                            torch.as_tensor(j, dtype=torch.int64)))\n",
    "        return indices\n",
    "\n",
    "\n",
    "class SimpleSetCriterion(nn.Module):\n",
    "    def __init__(self, num_classes, matcher, weight_dict):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.matcher = matcher\n",
    "        self.weight_dict = weight_dict\n",
    "        self.losses = [\"labels\", \"boxes\"]\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        pred_logits = outputs[\"pred_logits\"]  # [B, num_queries, num_classes]\n",
    "        pred_boxes = outputs[\"pred_boxes\"]    # [B, num_queries, 4]\n",
    "\n",
    "        indices = self.matcher(pred_logits, pred_boxes, targets)\n",
    "        loss_dict = {}\n",
    "\n",
    "        # Compute classification loss\n",
    "        loss_cls = 0\n",
    "        loss_bbox = 0\n",
    "\n",
    "        num_valid = 0\n",
    "        for b, (idx_pred, idx_tgt) in enumerate(indices):\n",
    "            if len(idx_pred) == 0 or len(idx_tgt) == 0:\n",
    "                continue\n",
    "\n",
    "            tgt_classes = targets[b][\"labels\"][idx_tgt]\n",
    "            pred_classes = pred_logits[b][idx_pred]\n",
    "            loss_cls += F.cross_entropy(pred_classes, tgt_classes)\n",
    "\n",
    "            tgt_boxes = targets[b][\"boxes\"][idx_tgt]\n",
    "            pred_bboxes = pred_boxes[b][idx_pred]\n",
    "            loss_bbox += F.l1_loss(pred_bboxes, tgt_boxes)\n",
    "\n",
    "            num_valid += 1\n",
    "\n",
    "        num_valid = max(num_valid, 1)\n",
    "        loss_dict[\"loss_ce\"] = loss_cls / num_valid\n",
    "        loss_dict[\"loss_bbox\"] = loss_bbox / num_valid\n",
    "\n",
    "\n",
    "        if \"pred_obj\" in outputs:\n",
    "            pred_obj = outputs[\"pred_obj\"]\n",
    "            target_obj = torch.zeros_like(pred_obj)\n",
    "            for b, (idx_pred, idx_tgt) in enumerate(indices):\n",
    "                target_obj[b, idx_pred] = 1.0\n",
    "            loss_obj = F.binary_cross_entropy_with_logits(pred_obj, target_obj)\n",
    "            loss_dict[\"loss_obj\"] = loss_obj\n",
    "            \n",
    "        total_loss = sum(loss_dict[k] * self.weight_dict.get(k, 1.0)\n",
    "                         for k in loss_dict)\n",
    "        return total_loss, loss_dict\n",
    "\n",
    "train_loader, test_loader = create_coco_dataloaders()\n",
    "\n",
    "model = MINDObjectDetector(\n",
    "    input_size=224,\n",
    "    num_heads=12,\n",
    "    dynamic_categories=91,\n",
    "    rank=32,\n",
    "    mode=\"supervised\",\n",
    "    adaptable_moe=True,\n",
    "    initial_vigilance=0.75,\n",
    "    vigilance_increment=0.05,\n",
    "    modality=\"object_detection\",\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model and loss to GPU\n",
    "model = model.to(device)\n",
    "criterion = SimpleSetCriterion(\n",
    "    num_classes=91,\n",
    "    matcher=SimpleMatcher(),\n",
    "    weight_dict={\n",
    "        \"loss_ce\": 1.0,\n",
    "        \"loss_bbox\": 5.0,\n",
    "        \"loss_obj\": 1.0,\n",
    "    }\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "from tqdm import tqdm\n",
    "for epoch in range(1):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    train_loop = tqdm(train_loader, desc=f\"[Epoch {epoch+1}] Training\", leave=False)\n",
    "\n",
    "    for images, targets in train_loop:\n",
    "        tensors, masks = images.decompose()\n",
    "\n",
    "        tensors = tensors.to(device)\n",
    "        masks = masks.to(device)\n",
    "        for tgt in targets:\n",
    "            tgt[\"boxes\"] = tgt[\"boxes\"].to(device)\n",
    "            tgt[\"labels\"] = tgt[\"labels\"].to(device)\n",
    "            tgt[\"size\"] = tgt[\"size\"].to(device)\n",
    "\n",
    "        outputs = model(tensors)\n",
    "\n",
    "        loss, loss_dict = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
