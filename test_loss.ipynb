{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e739e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "\n",
    "def focal_loss(inputs, targets, alpha=0.25, gamma=2.0):\n",
    "    p = F.softmax(inputs, -1)\n",
    "    ce = F.cross_entropy(inputs, targets, reduction=\"none\")\n",
    "    pt = p[torch.arange(len(targets), device=inputs.device), targets]\n",
    "\n",
    "    # down-weight background (assumed to be last class index)\n",
    "    alpha_factor = torch.full_like(pt, 1 - alpha)  # foreground gets higher weight\n",
    "    alpha_factor[targets == inputs.shape[-1] - 1] = alpha  # background gets lower weight\n",
    "\n",
    "    loss = alpha_factor * (1 - pt) ** gamma * ce\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "294f67f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal Loss: 0.012160624377429485\n",
      "Less Confident Focal Loss: 0.14292515814304352\n",
      "BG Loss (alpha=0.25): 0.0008353290613740683\n",
      "BG Loss (alpha=0.75): 0.0025059871841222048\n",
      "All focal loss tests passed âœ…\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def focal_loss(inputs, targets, alpha=0.25, gamma=2.0):\n",
    "    p = F.softmax(inputs, -1)\n",
    "    ce = F.cross_entropy(inputs, targets, reduction=\"none\")\n",
    "    pt = p[torch.arange(len(targets), device=inputs.device), targets]\n",
    "\n",
    "    alpha_factor = torch.full_like(pt, 1 - alpha)\n",
    "    alpha_factor[targets == inputs.shape[-1] - 1] = alpha\n",
    "\n",
    "    loss = alpha_factor * (1 - pt) ** gamma * ce\n",
    "    return loss.mean()\n",
    "\n",
    "# Confident predictions (correct)\n",
    "logits = torch.tensor([\n",
    "    [2.0, 0.5, 0.1],  # confident for class 0\n",
    "    [0.1, 2.0, 0.5],  # confident for class 1\n",
    "    [0.2, 0.3, 2.5],  # confident for background (class 2)\n",
    "], requires_grad=True)\n",
    "targets = torch.tensor([0, 1, 2])\n",
    "\n",
    "loss = focal_loss(logits, targets, alpha=0.25, gamma=2.0)\n",
    "print(\"Focal Loss:\", loss.item())\n",
    "\n",
    "# Less confident predictions\n",
    "less_confident_logits = torch.tensor([\n",
    "    [1.0, 1.0, 0.1],\n",
    "    [0.5, 1.0, 0.5],\n",
    "    [0.5, 0.5, 1.5],\n",
    "], requires_grad=True)\n",
    "less_confident_loss = focal_loss(less_confident_logits, targets, alpha=0.25, gamma=2.0)\n",
    "print(\"Less Confident Focal Loss:\", less_confident_loss.item())\n",
    "\n",
    "# Background-only test\n",
    "bg_logits = torch.tensor([\n",
    "    [0.2, 0.3, 2.5],\n",
    "    [0.1, 0.2, 2.7],\n",
    "    [0.0, 0.1, 2.8],\n",
    "], requires_grad=True)\n",
    "bg_targets = torch.tensor([2, 2, 2])\n",
    "\n",
    "bg_loss_low_alpha = focal_loss(bg_logits, bg_targets, alpha=0.25, gamma=2.0)\n",
    "bg_loss_high_alpha = focal_loss(bg_logits, bg_targets, alpha=0.75, gamma=2.0)\n",
    "\n",
    "print(\"BG Loss (alpha=0.25):\", bg_loss_low_alpha.item())\n",
    "print(\"BG Loss (alpha=0.75):\", bg_loss_high_alpha.item())\n",
    "\n",
    "# âœ… Assertions\n",
    "assert loss.item() > 0, \"Loss should be positive\"\n",
    "assert less_confident_loss > loss, \"Less confident predictions should have higher loss\"\n",
    "assert bg_loss_low_alpha < bg_loss_high_alpha, \"Lower alpha should reduce background loss\"\n",
    "\n",
    "print(\"All focal loss tests passed âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dad2a68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Prediction Focal Loss: 1.271703839302063\n",
      "Focal Loss (correct): 0.012160624377429485\n"
     ]
    }
   ],
   "source": [
    "# Completely wrong predictions\n",
    "# Each sample predicts the wrong class with high confidence\n",
    "wrong_logits = torch.tensor([\n",
    "    [0.1, 2.5, 0.2],  # should be class 0\n",
    "    [2.5, 0.1, 0.2],  # should be class 1\n",
    "    [2.5, 0.1, 0.2],  # should be class 2 (bg), but predicts class 0\n",
    "], requires_grad=True)\n",
    "wrong_targets = torch.tensor([0, 1, 2])\n",
    "\n",
    "wrong_loss = focal_loss(wrong_logits, wrong_targets, alpha=0.25, gamma=2.0)\n",
    "print(\"Wrong Prediction Focal Loss:\", wrong_loss.item())\n",
    "\n",
    "# ðŸ” Compare against confident correct predictions\n",
    "print(\"Focal Loss (correct):\", loss.item())\n",
    "assert wrong_loss > loss, \"Loss should increase when predictions are very wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a99fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background-Only Loss: 0.0008353290613740683\n",
      "Background-Only Loss with alpha=0.75: 0.0025059871841222048\n"
     ]
    }
   ],
   "source": [
    "# Check that background samples are being weighted with alpha\n",
    "bg_logits = torch.tensor([\n",
    "    [0.2, 0.3, 2.5],\n",
    "    [0.1, 0.2, 2.7],\n",
    "    [0.0, 0.1, 2.8],\n",
    "], requires_grad=True)\n",
    "\n",
    "bg_targets = torch.tensor([2, 2, 2])\n",
    "\n",
    "bg_only_loss = focal_loss(bg_logits, bg_targets, alpha=0.25, gamma=2.0)\n",
    "print(\"Background-Only Loss:\", bg_only_loss.item())\n",
    "\n",
    "# Now flip the alpha and see if it's higher (to test alpha impact)\n",
    "fg_heavy_loss = focal_loss(bg_logits, bg_targets, alpha=0.75, gamma=2.0)\n",
    "print(\"Background-Only Loss with alpha=0.75:\", fg_heavy_loss.item())\n",
    "\n",
    "assert bg_only_loss.item() < fg_heavy_loss.item(), \"Lower alpha should reduce background loss\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
